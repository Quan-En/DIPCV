{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import array, zeros\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.fftpack import dct, idct\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from BATCH_DCT_DETECT import DCT_DETECT\n",
    "# from utils import GetFeature, GetPathList, GetPlotDF, GetBalanceTrainArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dct_detect = DCT_DETECT()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Image features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Generate features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_path = \"/home/re6091054/FF++/c40/train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"ff_train_raw.txt\", \"r\") as f:\n",
    "#     text = f.read()\n",
    "# text = [sub_text.split(\" \") for sub_text in text.split(\"\\n\")][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deepfakes_folder = [train_data_path + \"/\" + folder_name for folder_name, y in text][(180*0)+(720*0):(180*1)+(720*0)]\n",
    "# Face2Face_folder = [train_data_path + \"/\" + folder_name for folder_name, y in text][(180*1)+(720*1):(180*2)+(720*1)]\n",
    "# FaceSwap_folder = [train_data_path + \"/\" + folder_name for folder_name, y in text][(180*2)+(720*2):(180*3)+(720*2)]\n",
    "# NeuralTextures_folder = [train_data_path + \"/\" + folder_name for folder_name, y in text][(180*3)+(720*3):(180*4)+(720*3)]\n",
    "# Real_folder = [train_data_path + \"/\" + folder_name for folder_name, y in text][(720*4):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder_list = [Deepfakes_folder, Face2Face_folder, FaceSwap_folder,  NeuralTextures_folder, Real_folder]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for folder_type in tqdm(folder_list):\n",
    "#     images_list = []\n",
    "#     for folder_path in folder_type:\n",
    "#         images_list.append(cv2.imread(folder_path + \"/0.png\"))\n",
    "#     features_list.append(my_dct_detect.main(images_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_arr = np.row_stack(features_list)\n",
    "\n",
    "# response_arr = np.array(\n",
    "#     [1] * 720 + \n",
    "#     [0] * 720\n",
    "# )\n",
    "\n",
    "# image_type_arr = np.array(\n",
    "#     [\"Deepfakes\"] * 180 + \n",
    "#     [\"Face2Face\"] * 180 + \n",
    "#     [\"FaceSwap\"] * 180 + \n",
    "#     [\"NeuralTextures\"] * 180 + \n",
    "#     [\"Real\"] * 720\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(\"data/features_arr.npy\", features_arr)\n",
    "# np.save(\"data/response_arr.npy\", response_arr)\n",
    "# np.save(\"data/image_type_arr.npy\", image_type_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Load features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_arr = np.load(\"data/features_arr.npy\")\n",
    "response_arr = np.load(\"data/response_arr.npy\")\n",
    "image_type_arr = np.load(\"data/image_type_arr.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_features_arr = np.load(\"/home/re6091054/影像處理與電腦視覺/fianl_compression/data/train_features_Conv_trace_arr.npy\")\n",
    "conv_response_arr = np.load(\"/home/re6091054/影像處理與電腦視覺/fianl_compression/data/train_response_arr.npy\")\n",
    "conv_image_type_arr = np.load(\"/home/re6091054/影像處理與電腦視覺/fianl_compression/data/train_image_type_arr.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features_arr = np.column_stack([features_arr, conv_features_arr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1440, 87)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_features_arr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, auc, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1. Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=2000)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_reg = LogisticRegression(penalty='l2', max_iter=2000)\n",
    "l_reg.fit(cat_features_arr, response_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "\n",
    "ax.bar(list(range(87)), l_reg.coef_.reshape(-1))\n",
    "ax.set_ylabel(\"Magnitude\")\n",
    "ax.set_title(\"Coefficient magnitude\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3. Xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.1. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_train = xgb.DMatrix(cat_features_arr, response_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.2. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'objective':'binary:logistic', 'eval_metric':'logloss'}\n",
    "xgb_model = xgb.train(params, xg_train, verbose_eval=True) # , 30, xgb_model=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train AUC 0.9877 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "fpr, tpr, thresholds = roc_curve(response_arr, xgb_model.predict(xg_train), pos_label=1)\n",
    "print(\"Train AUC\", round(auc(fpr, tpr), 4), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight_ratio = float(len(train_y_001_array[train_y_001_array == 0])) / float(len(train_y_001_array[train_y_001_array == 1]))\n",
    "# w_array = np.array([weight_ratio] * train_y_001_array.shape[0])\n",
    "# w_array[train_y_001_array == 0] = 1- weight_ratio\n",
    "\n",
    "# xgb_model.fit(X=train_x_001_array, y=train_y_001_array.astype(int), sample_weight=w_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Testing ACC: \", round(accuracy_score(train_y_1, xgb_model.predict(train_x_1)), 4))\n",
    "# print(\"Testing Confusion matrix: \\n\", confusion_matrix(train_y_1, xgb_model.predict(train_x_1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_path = '/home/re6091054/FF++/c40/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_types = sorted(os.listdir(test_data_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_features_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for img_typ in tqdm(image_types):\n",
    "#     type_name = test_data_path + \"/\" + img_typ\n",
    "#     folders_list = os.listdir(type_name)\n",
    "#     imags_list = []\n",
    "#     for folder in folders_list:\n",
    "#         folder_name = type_name + \"/\" + folder\n",
    "#         imags_list.append(cv2.imread(folder_name + \"/0.png\"))\n",
    "#     test_features_list.append(my_dct_detect.main(imags_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(map(lambda x: x.shape, test_features_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_features_arr = np.row_stack(test_features_list)\n",
    "# test_response_arr = np.array(\n",
    "#     [1] * 140 * 4 +\n",
    "#     [0] * 140\n",
    "# )\n",
    "# test_image_type_arr = np.array(\n",
    "#     [\"Deepfakes\"] * 140 + \n",
    "#     [\"Face2Face\"] * 140 + \n",
    "#     [\"FaceSwap\"] * 140 + \n",
    "#     [\"NeuralTextures\"] * 140 + \n",
    "#     [\"Real\"] * 140\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(\"data/test_features_arr.npy\", test_features_arr)\n",
    "# np.save(\"data/test_response_arr.npy\", test_response_arr)\n",
    "# np.save(\"data/test_image_type_arr.npy\", test_image_type_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features_arr = np.load(\"data/test_features_arr.npy\")\n",
    "test_response_arr = np.load(\"data/test_response_arr.npy\")\n",
    "test_image_type_arr = np.load(\"data/test_image_type_arr.npy\")\n",
    "test_conv_features_arr = np.load(\"/home/re6091054/影像處理與電腦視覺/fianl_compression/data/test_features_conv_trace_arr.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cat_features_arr = np.column_stack([test_features_arr, test_conv_features_arr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing ACC:  0.5557 \n",
      "\n",
      "Testing confusion matrix: \n",
      " [[ 76 247]\n",
      " [ 64 313]] \n",
      "\n",
      "Testing AUC 0.5632 \n",
      "\n",
      "F1:  0.49819169215662323\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing ACC: \", round(accuracy_score(l_reg.predict(test_cat_features_arr), test_response_arr), 4), \"\\n\")\n",
    "print(\"Testing confusion matrix: \\n\", confusion_matrix(l_reg.predict(test_cat_features_arr), test_response_arr), \"\\n\")\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(test_response_arr, l_reg.predict_proba(test_cat_features_arr)[:,1], pos_label=1)\n",
    "print(\"Testing AUC\", round(auc(fpr, tpr), 4), \"\\n\")\n",
    "\n",
    "print(\"F1: \", f1_score(test_response_arr, l_reg.predict(test_cat_features_arr), average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_test = xgb.DMatrix(test_cat_features_arr, test_response_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_prob = xgb_model.predict(xg_test)\n",
    "test_pred = np.round(test_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing ACC:  0.5429 \n",
      "\n",
      "Testing confusion matrix: \n",
      " [[ 62 242]\n",
      " [ 78 318]] \n",
      "\n",
      "Testing AUC 0.5166 \n",
      "\n",
      "F1:  0.472275622903238\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing ACC: \", round(accuracy_score(test_pred, test_response_arr), 4), \"\\n\")\n",
    "print(\"Testing confusion matrix: \\n\", confusion_matrix(test_pred, test_response_arr), \"\\n\")\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(test_response_arr, test_pred_prob, pos_label=1)\n",
    "print(\"Testing AUC\", round(auc(fpr, tpr), 4), \"\\n\")\n",
    "\n",
    "print(\"F1: \", f1_score(test_response_arr, test_pred, average='macro'))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f60de7e7255f4ab527b986eaf60aa68ccde8f505bf7ee0c2840f8bd30402111f"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
